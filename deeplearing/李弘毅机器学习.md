## 李弘毅机器学习

### gradient descent

Adagradient descent

### Classification

1.how to do classification?

training data (x1, $y1$)

找到 function g(x) 大于0为class1，else class 2

loss function 

训练时候预测错误的次数

others  Perceptron , SVM   not today

使用生成模型进行预测（使用贝叶斯）

假设宝可梦的分布服从高斯分布

激活函数是由后验概率公式推导出来的

wx+b是由服从高斯分布的概率公式推导出来的

概率和神经网络是有联系的



### Logistic Regression

 逻辑回归和线性回归的差别是多了一个激活函数

分类问题问题符合伯努利分布，它的损失函数是交叉熵。

线性回归的损失函数是L2损失函数



### Deep Learning

### Backpropagation







